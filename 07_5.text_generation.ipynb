{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API：\n",
    "# tf.random.categorical #随机采样\n",
    "# tf.expand_dims(input_eval, 0)#增加维度\n",
    "# tf.squeeze(predictions, 0)#减少维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "print(tf.__name__, tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# url = 'http://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    "\n",
    "# r = requests.get(url)\n",
    "# # print(r.text)\n",
    "# with open('data/shakespeare.txt','w') as f:\n",
    "#     f.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# http://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
    "input_filepath = \"data/shakespeare.txt\"\n",
    "text = open(input_filepath, 'r').read()\n",
    "\n",
    "print(len(text))\n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# 数据处理\n",
    "# 1.generate vocab\n",
    "# 2.build mapping char ->id\n",
    "# 3.data -> id_data\n",
    "# 4.abcd  -> bcd<eos>\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "print(len(vocab))\n",
    "print(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列\n",
    "print(char_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "idx_to_char = np.array(vocab)\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n"
     ]
    }
   ],
   "source": [
    "text_as_int = np.array([char_to_idx[c] for c in text])\n",
    "print(text_as_int[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int64) F\n",
      "tf.Tensor(47, shape=(), dtype=int64) i\n",
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int64)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49], shape=(101,), dtype=int64)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(id_text):\n",
    "    # 4.abcde  -> abcd, bcde\n",
    "    return id_text[0:-1],  id_text[1:]\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "seq_length = 100\n",
    "seq_dataset = char_dataset.batch(seq_length + 1, \n",
    "                                                 drop_remainder = True)\n",
    "# drop_remainder 做batch最后如果不够就丢掉\n",
    "for ch_id in char_dataset.take(2):\n",
    "    print(ch_id, idx_to_char[ch_id.numpy()])\n",
    "for seq_id in seq_dataset.take(2):\n",
    "    print(seq_id)\n",
    "    print(repr(''.join(idx_to_char[seq_id.numpy()])))# repr 显示特殊字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1]\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1]\n",
      "[56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1 58\n",
      " 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0 13\n",
      " 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8  0\n",
      "  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1 63\n",
      " 53 59  1 49]\n"
     ]
    }
   ],
   "source": [
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "\n",
    "for item_input, item_output in seq_dataset.take(2):\n",
    "    print(item_input.numpy())\n",
    "    print(item_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "seq_dataset = seq_dataset.shuffle(buffer_size).batch(\n",
    "                      batch_size, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (64, None, 1024)          1311744   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 1,395,009\n",
      "Trainable params: 1,395,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units,batch_size):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape = [batch_size, None]),\n",
    "        keras.layers.SimpleRNN(units= rnn_units,\n",
    "                                          return_sequences = True),\n",
    "        keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "        vocab_size = vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        rnn_units = rnn_units,\n",
    "        batch_size=batch_size\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65)\n"
     ]
    }
   ],
   "source": [
    "# 用定义好的模型做预测\n",
    "for input_example_batch, target_example_batch in seq_dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[31]\n",
      " [ 7]\n",
      " [46]\n",
      " [55]\n",
      " [64]\n",
      " [11]\n",
      " [29]\n",
      " [35]\n",
      " [22]\n",
      " [50]\n",
      " [50]\n",
      " [26]\n",
      " [57]\n",
      " [18]\n",
      " [15]\n",
      " [25]\n",
      " [ 1]\n",
      " [33]\n",
      " [38]\n",
      " [56]\n",
      " [41]\n",
      " [56]\n",
      " [26]\n",
      " [10]\n",
      " [29]\n",
      " [35]\n",
      " [20]\n",
      " [12]\n",
      " [22]\n",
      " [42]\n",
      " [14]\n",
      " [ 9]\n",
      " [29]\n",
      " [26]\n",
      " [ 6]\n",
      " [61]\n",
      " [ 2]\n",
      " [18]\n",
      " [49]\n",
      " [33]\n",
      " [48]\n",
      " [34]\n",
      " [20]\n",
      " [43]\n",
      " [51]\n",
      " [62]\n",
      " [10]\n",
      " [48]\n",
      " [29]\n",
      " [10]\n",
      " [64]\n",
      " [61]\n",
      " [46]\n",
      " [51]\n",
      " [17]\n",
      " [11]\n",
      " [ 4]\n",
      " [18]\n",
      " [51]\n",
      " [46]\n",
      " [34]\n",
      " [47]\n",
      " [ 2]\n",
      " [55]\n",
      " [12]\n",
      " [ 6]\n",
      " [49]\n",
      " [21]\n",
      " [16]\n",
      " [44]\n",
      " [28]\n",
      " [22]\n",
      " [30]\n",
      " [44]\n",
      " [47]\n",
      " [ 9]\n",
      " [46]\n",
      " [54]\n",
      " [ 6]\n",
      " [64]\n",
      " [20]\n",
      " [46]\n",
      " [55]\n",
      " [18]\n",
      " [50]\n",
      " [20]\n",
      " [ 7]\n",
      " [27]\n",
      " [ 4]\n",
      " [56]\n",
      " [18]\n",
      " [11]\n",
      " [55]\n",
      " [46]\n",
      " [47]\n",
      " [53]\n",
      " [32]\n",
      " [37]\n",
      " [29]\n",
      " [37]], shape=(100, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#随机采样，random sampling\n",
    "#greedy贪心策略，random随机策略\n",
    "sample_indices = tf.random.categorical(\n",
    "    logits = example_batch_predictions[0], num_samples = 1)\n",
    "print(sample_indices)\n",
    "#(100, 65) -> (100, 1)\n",
    "sample_indices = tf.squeeze(sample_indices, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 'der,\\nAnd issue forth and bid them battle straight.\\n\\nYORK:\\nFive men to twenty! though the odds be gre'\n",
      "\n",
      "Output 'er,\\nAnd issue forth and bid them battle straight.\\n\\nYORK:\\nFive men to twenty! though the odds be grea'\n",
      "\n",
      "Predictions 'S-hqz;QWJllNsFCM UZrcrN:QWH?JdB3QN,w!FkUjVHemx:jQ:zwhmE;&FmhVi!q?,kIDfPJRfi3hp,zHhqFlH-O&rF;qhioTYQY'\n"
     ]
    }
   ],
   "source": [
    "print('Input', repr(\"\".join(idx_to_char[input_example_batch[0]])))\n",
    "print()\n",
    "print('Output', repr(\"\".join(idx_to_char[target_example_batch[0]])))\n",
    "print()\n",
    "print('Predictions', repr(\"\".join(idx_to_char[sample_indices])))\n",
    "# 模型还没有训练，Predictions打出无需字母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "4.185625\n"
     ]
    }
   ],
   "source": [
    "# 自定义损失函数\n",
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "            labels, logits, from_logits = True)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = loss)\n",
    "example_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(example_loss.shape)\n",
    "print(example_loss.numpy().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 9s 55ms/step - loss: 2.8151\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 2.1992\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.9991\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 9s 52ms/step - loss: 1.8556\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 9s 50ms/step - loss: 1.7472\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.6656\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.6064\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 9s 50ms/step - loss: 1.5514\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.5103\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.4779\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 9s 50ms/step - loss: 1.4492\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.4252\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.4029\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.3863\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.3674\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.3518\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.3396\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.3239\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.3117\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.3001\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2891\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2761\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2644\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2539\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2449\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2345\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2230\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2122\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.2036\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1933\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 9s 52ms/step - loss: 1.1835\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 9s 54ms/step - loss: 1.1743\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1647\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1564\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1479\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1374\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1297\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1229\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1135\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.1032\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 9s 52ms/step - loss: 1.0959\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 9s 50ms/step - loss: 1.0903\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.0827\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.0748\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.0680\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 9s 52ms/step - loss: 1.0611\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.0535\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.0487\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.0444\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 9s 51ms/step - loss: 1.0376\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "output_dir = 'data/text_generation_lstm'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "checkpoint_prefix = os.path.join(output_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = checkpoint_prefix,\n",
    "        save_weights_only = True)\n",
    "\n",
    "epochs = 50\n",
    "history = model.fit(seq_dataset, epochs = epochs,\n",
    "                           callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/text_generation_lstm/ckpt_50'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看最新保存的模型tf.train.latest_checkpoint\n",
    "tf.train.latest_checkpoint(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (1, None, 1024)           1311744   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 1,395,009\n",
      "Trainable params: 1,395,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 从checkpoint载入模型\n",
    "model2  = build_model(vocab_size,\n",
    "                                 embedding_dim,\n",
    "                                 rnn_units,\n",
    "                                 batch_size = 1)\n",
    "model2.load_weights(tf.train.latest_checkpoint(output_dir))\n",
    "model2.build(tf.TensorShape([1, None]))\n",
    "# 文本生成流程：\n",
    "# start ch sequence A,\n",
    "# A -> model -> b\n",
    "# A -> append(b) -> B\n",
    "# B -> model -> c\n",
    "# B -> append(c) -> C\n",
    "# C -> model -> ....\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: t'b''''''''''''t''''''''t'''tt''t''tt''t''t'''t''t'''t''t't'ht'tttt'tt'''tt''t''''''t''''''btt'tt'''ttt''a't''''tt'ht'tt'''t't''tt'tt'tmt'b'''t''m'''''t'''t'''t't''bttt''''t't'tttt'''''''tttT'atttt't''tt'''''t't''''tmt'tt'b''''t't''t'tt''''ttt't'''t'tt'tttt''tb'tt'It''t'''''t't''Itt'It''t''tt''ttbt't'''t't'tm'ttt'''ttt'''t''t''tt't''t'ttt't''''tttttt't'''t''''I''st''''t''''tttttttt''t'''s''''''t'ttb't''tSt''''t''t'''tt'btt'It'''tbtt''ttt'tt''tt'''''tt'tttttt''''t'''t''tt't't't''tt't''t'''t''tt'I''t''t'tI'tt'b't''''tt''t'''m'''t''tt't't''tI''ttt''H''tt't'tSt''t'''t'''b'''''t'''t'II''ttt''tttt''t't'tt'tt't'''tt'b''''tt''''tttt''''t''''''t''ttt't'''''t't'''tt't''''tttt't''t'''HtI''tt'''''t''t'tmt'''t't'tt'''t''t'''t'''t'tmt't'ttt't'''''m''tt''''t't'tt't'tm'''tt'tItt'''''t'''''tmtt't'tt''tt'''t''tt''t't''tb''t''I'''tH'b''tt't''tt't''t''tt'tttt'tkt'''t't't't't''tt't''tt'b'''tthtt'ttttt't't''tT''tHt'tt't'bTIIHtts'ttt'tm't't't't'tm''mt''I'ttt''t't't'tt''''ttts't''Im'ttt'ttt''ttt'tI'''tmt'''tt\n"
     ]
    }
   ],
   "source": [
    "# 利用模型生成文本\n",
    "def generata_text(model, start_string, num_genetate = 1000):\n",
    "    input_eval = [char_to_idx[ch] for ch in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)#增加维度\n",
    "    \n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    temperature =0.5\n",
    "    \n",
    "    for _ in range(num_genetate):\n",
    "        # 1. model inference -> predictions\n",
    "        # 2. sample -> ch -> text_generated.\n",
    "        # 3. update input_evel\n",
    "        # predictions : [batch_size, input_eval_len, vocab_size]\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        predictions = predictions/temperature\n",
    "        # predictions : [input_eval_len, vocab_size]\n",
    "        predictions = tf.squeeze(predictions, 0)#减少维度\n",
    "        # predictions : [input_eval_len, 1]\n",
    "        # a b c ->  b c d\n",
    "        predictions_id = tf.random.categorical(\n",
    "                predictions, num_samples=1)[-1,0].numpy()\n",
    "        text_generated.append(idx_to_char[predictions_id])\n",
    "        input_evel = tf.expand_dims([predictions_id], 0)\n",
    "    return start_string + ''.join(text_generated)\n",
    "\n",
    "new_text = generata_text(model2, \"All: \")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
