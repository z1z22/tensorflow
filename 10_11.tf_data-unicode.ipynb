{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oL9KopJirB2g"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "SKaX3Hd3ra6C"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXH1bmUctMld"
   },
   "source": [
    "# Unicode strings\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/unicode\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/unicode.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/unicode.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/load_data/unicode.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrHJrKYis06U"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Models that process natural language often handle different languages with different character sets.  *Unicode* is a standard encoding system that is used to represent character from almost all languages.  Each character is encoded using a unique integer [code point](https://en.wikipedia.org/wiki/Code_point) between `0` and `0x10FFFF`. A *Unicode string* is a sequence of zero or more code points.\n",
    "\n",
    "This tutorial shows how to represent Unicode strings in TensorFlow and manipulate them using Unicode equivalents of standard string ops. It separates Unicode strings into tokens based on script detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIKHl5Lvn4gh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-LkcI-vtWNj"
   },
   "source": [
    "## The `tf.string` data type\n",
    "\n",
    "The basic TensorFlow `tf.string` `dtype` allows you to build tensors of byte strings.\n",
    "Unicode strings are utf-8 encoded by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yo-Qv6ntaFr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"Thanks üòä\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kA1ziG2tyCT"
   },
   "source": [
    "A `tf.string` tensor can hold byte strings of varying lengths because the byte strings are treated as atomic units. The string length is not included in the tensor dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyINCmTztyyS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([\"You're\",  \"welcome!\"]).shape#python3ÈªòËÆ§ÁºñÁ†ÅÂ∑≤ÁªèÊòØutf-8Ôºå‰∏çÁî®Âä†u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsMPnjb6UDJ1"
   },
   "source": [
    "Note: When using python to construct strings, the handling of unicode differs betweeen v2 and v3. In v2, unicode strings are indicated by the \"u\" prefix, as above. In v3, strings are unicode-encoded by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hUFZ7B1Lk-uj"
   },
   "source": [
    "## Representing Unicode\n",
    "\n",
    "There are two standard ways to represent a Unicode string in TensorFlow:\n",
    "\n",
    "* `string` scalar ‚Äî where the sequence of code points is encoded using a known [character encoding](https://en.wikipedia.org/wiki/Character_encoding).\n",
    "* `int32` vector ‚Äî where each position contains a single code point.\n",
    "\n",
    "For example, the following three values all represent the Unicode string `\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"` (which means \"language processing\" in Chinese):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjQIkfJWvC_u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQqcUECcvF2r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExdBr1t7vMuS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a vector of Unicode code points.\n",
    "# ord()ËøîÂõûÂØπÂ∫îÁöÑ ASCII Êï∞ÂÄºÔºåÊàñËÄÖ Unicode Êï∞ÂÄºint32Ôºå\n",
    "text_chars = tf.constant([ord(char) for char in \"ËØ≠Ë®ÄÂ§ÑÁêÜ\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8czv4JNpBnZ"
   },
   "source": [
    "# Áõ∏‰∫íËΩ¨Êç¢\n",
    "### Converting between representations\n",
    "\n",
    "TensorFlow provides operations to convert between these different representations:\n",
    "\n",
    "* `tf.strings.unicode_decode`: Â∞ÜÁºñÁ†ÅÁöÑÂ≠óÁ¨¶‰∏≤Ê†áÈáèËΩ¨Êç¢‰∏∫‰ª£Á†ÅÁÇπÁöÑÂêëÈáè„ÄÇ\n",
    "* `tf.strings.unicode_encode`: Â∞Ü‰ª£Á†ÅÁÇπÂêëÈáèËΩ¨Êç¢‰∏∫ÁºñÁ†ÅÁöÑÂ≠óÁ¨¶‰∏≤Ê†áÈáè„ÄÇ\n",
    "* `tf.strings.unicode_transcode`: Â∞ÜÁºñÁ†ÅÂêéÁöÑÂ≠óÁ¨¶‰∏≤Ê†áÈáèËΩ¨Êç¢‰∏∫ÂÖ∂‰ªñÁºñÁ†Å„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qb-UQ_oLpAJg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=11, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8,\n",
    "                          input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEBUcunnp-9n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars,\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MLhWcLZrph-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8,\n",
    "                             input_encoding='UTF8',\n",
    "                             output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVeLeVohqN7I"
   },
   "source": [
    "### Batch dimensions\n",
    "\n",
    "Ëß£Á†ÅÂ§ö‰∏™Â≠óÁ¨¶‰∏≤Êó∂ÔºåÊØè‰∏™Â≠óÁ¨¶‰∏≤‰∏≠ÁöÑÂ≠óÁ¨¶Êï∞ÂèØËÉΩ‰∏çÁõ∏Á≠â„ÄÇËøîÂõûÁªìÊûúÊòØ`tf.RaggedTensor`ÔºåÂÖ∂‰∏≠ÊúÄÈáåÈù¢ÁöÑÁª¥ÁöÑÈïøÂ∫¶Ê†πÊçÆÊØè‰∏™Â≠óÁ¨¶‰∏≤‰∏≠ÁöÑÂ≠óÁ¨¶Êï∞ËÄåÂèòÂåñÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2jVzPymr_Mm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104, 195, 108, 108, 111], [87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119], [71, 246, 246, 100, 110, 105, 103, 104, 116], [128522]]\n",
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "              ['h√Éllo',  'What is the weather tomorrow',  'G√∂√∂dnight', 'üòä']]\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "\n",
    "print(batch_chars_ragged.to_list())\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "  print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRh3n1hPsJ9v"
   },
   "source": [
    "ÊÇ®ÂèØ‰ª•tf.RaggedTensorÁõ¥Êé•‰ΩøÁî®Ê≠§Ê†ºÂºèÔºå‰πüÂèØ‰ª•‰ΩøÁî®tf.TensorpaddingÊàñtf.SparseTensor‰ΩøÁî®ÊñπÊ≥ïtf.RaggedTensor.to_tensorÂíåÂ∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫ÂØÜÈõÜÊ†ºÂºètf.RaggedTensor.to_sparse„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yz17yeSMsUid"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "# tf.RaggedTensor.to_tensor\n",
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBjsPQp3rhfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 1  0]\n",
      " [ 1  1]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 1  4]\n",
      " [ 1  5]\n",
      " [ 1  6]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 13]\n",
      " [ 1 14]\n",
      " [ 1 15]\n",
      " [ 1 16]\n",
      " [ 1 17]\n",
      " [ 1 18]\n",
      " [ 1 19]\n",
      " [ 1 20]\n",
      " [ 1 21]\n",
      " [ 1 22]\n",
      " [ 1 23]\n",
      " [ 1 24]\n",
      " [ 1 25]\n",
      " [ 1 26]\n",
      " [ 1 27]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 2  3]\n",
      " [ 2  4]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2  7]\n",
      " [ 2  8]\n",
      " [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n",
      "[   104    195    108    108    111     87    104     97    116     32\n",
      "    105    115     32    116    104    101     32    119    101     97\n",
      "    116    104    101    114     32    116    111    109    111    114\n",
      "    114    111    119     71    246    246    100    110    105    103\n",
      "    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# tf.RaggedTensor.to_sparse\n",
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "print(batch_chars_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCCkZh-nwlbL"
   },
   "source": [
    "Âú®ÂØπÂ§ö‰∏™ÂÖ∑ÊúâÁõ∏ÂêåÈïøÂ∫¶ÁöÑÂ≠óÁ¨¶‰∏≤ËøõË°åÁºñÁ†ÅÊó∂Ôºåtf.TensorÂèØ‰ª•Â∞ÜaÁî®‰ΩúËæìÂÖ•Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lP62YUAwjK9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=784, shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w58CMRg9tamW"
   },
   "source": [
    "ÂØπÈïøÂ∫¶ÂèØÂèòÁöÑÂ§ö‰∏™Â≠óÁ¨¶‰∏≤ËøõË°åÁºñÁ†ÅÊó∂ÔºåÂ∫îÂ∞Üa tf.RaggedTensorÁî®‰ΩúËæìÂÖ•Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7GtOtrltaMl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2Nh5Aj9xob3"
   },
   "source": [
    "If you have a tensor with multiple strings in padded or sparse format, then convert it to a `tf.RaggedTensor` before calling `unicode_encode`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2bYCYl0u-Ue"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=863, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlV2znh_u_zm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=936, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQOOGkscvDpc"
   },
   "source": [
    "## Unicode operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NkmtsA_yvMB0"
   },
   "source": [
    "### Â≠óÁ¨¶ÈïøÂ∫¶\n",
    "ËØ•tf.strings.lengthÊìç‰ΩúÂÖ∑Êúâ‰∏Ä‰∏™ÂèÇÊï∞unitÔºåËØ•ÂèÇÊï∞ÊåáÁ§∫Â∫îÂ¶Ç‰ΩïËÆ°ÁÆóÈïøÂ∫¶„ÄÇ unitÈªòËÆ§‰∏∫\"BYTE\"Ôºå‰ΩÜÂèØ‰ª•Â∞ÜÂÖ∂ËÆæÁΩÆ‰∏∫ÂÖ∂‰ªñÂÄºÔºå‰æãÂ¶Ç\"UTF8_CHAR\"Êàñ\"UTF16_CHAR\"Ôºå‰ª•Á°ÆÂÆöÊØè‰∏™Â∑≤ÁºñÁ†ÅÁöÑUnicode‰ª£Á†ÅÁÇπÁöÑÊï∞Èáèstring„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZzMe59mvLHr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; 8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# ËØ∑Ê≥®ÊÑèÔºåÊúÄÂêé‰∏Ä‰∏™Â≠óÁ¨¶Âú®UTF8‰∏≠Âç†Áî®4‰∏™Â≠óËäÇ\n",
    "thanks = 'Thanks üòä'.encode('UTF-8')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHG85gxlvVU0"
   },
   "source": [
    "### Character substrings\n",
    "\n",
    "ËØ•tf.strings.substrÊìç‰ΩúÊé•Âèó‚Äú unit‚ÄùÂèÇÊï∞ÔºåÂπ∂‰ΩøÁî®ÂÆÉÊù•Á°ÆÂÆö‚Äú pos‚ÄùÂíå‚Äú len‚ÄùÂèÇÊï∞ÂåÖÂê´ÁöÑÂÅèÁßªÈáè„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlWRLV-4xWYq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: unit='BYTE'. With len=1, we return a single byte.\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfNUVDPwxkCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xf0\\x9f\\x98\\x8a'\n"
     ]
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', we return a single character, which in this case\n",
    "# is 4 bytes.\n",
    "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJUEsVSyeIa3"
   },
   "source": [
    "### Split Unicode strings\n",
    "\n",
    "ÊãÜÂàÜUnicodeÂ≠óÁ¨¶‰∏≤,T `tf.strings.unicode_split` Â∞ÜunicodeÂ≠óÁ¨¶‰∏≤ÊãÜÂàÜ‰∏∫ÂêÑ‰∏™Â≠óÁ¨¶ÁöÑÂ≠êÂ≠óÁ¨¶‰∏≤Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDjkh5G1ejMt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQqEEZEbdG9O"
   },
   "source": [
    "### Â≠óÁ¨¶ÁöÑÂ≠óËäÇÂÅèÁßª\n",
    "\n",
    "‰∏∫‰∫ÜÂ∞ÜÁîüÊàêÁöÑÂ≠óÁ¨¶Âº†Èáètf.strings.unicode_decode‰∏éÂéüÂßãÂ≠óÁ¨¶‰∏≤ÂØπÈΩêÔºå‰∫ÜËß£ÊØè‰∏™Â≠óÁ¨¶ÂºÄÂßã‰ΩçÁΩÆÁöÑÂÅèÁßªÈáèÂæàÊúâÁî®„ÄÇËØ•ÊñπÊ≥ïtf.strings.unicode_decode_with_offsetsÁ±ª‰ºº‰∫éunicode_decodeÔºåÈô§‰∫ÜÂÆÉËøîÂõûÂåÖÂê´ÊØè‰∏™Â≠óÁ¨¶ÁöÑËµ∑ÂßãÂÅèÁßªÈáèÁöÑÁ¨¨‰∫åÂº†Èáè„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cug7cmwYdowd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint 127880\n",
      "At byte offset 4: codepoint 127881\n",
      "At byte offset 8: codepoint 127882\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(\"üéàüéâüéä\", 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "  print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))#ËæìÂá∫ÂÅèÁßªÈáèÔºåÂíåÂÄº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZnCNxOvx66T"
   },
   "source": [
    "## Unicode scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRRHqkqNyGZ6"
   },
   "source": [
    "ÊØè‰∏™Unicode‰ª£Á†ÅÁÇπÈÉΩÂ±û‰∫é‰∏Ä‰∏™Áß∞‰∏∫ËÑöÊú¨ÔºàscriptsÔºâÁöÑ‰ª£Á†ÅÁÇπÁöÑÂçï‰∏™ÈõÜÂêà„ÄÇËßíËâ≤ÁöÑËÑöÊú¨ÊúâÂä©‰∫éÁ°ÆÂÆöËßíËâ≤ÂèØËÉΩ‰ΩøÁî®ÁöÑËØ≠Ë®Ä„ÄÇ‰æãÂ¶ÇÔºåÁü•ÈÅìË•øÈáåÂ∞îÂ≠óÊØç‰∏∫‚Äú–ë‚ÄùÊó∂ÔºåË°®ÊòéÂåÖÂê´ËØ•ËßíËâ≤ÁöÑÁé∞‰ª£ÊñáÊú¨ÂæàÂèØËÉΩÊù•Ëá™ÊñØÊãâÂ§´ËØ≠Ôºå‰æãÂ¶Ç‰øÑËØ≠Êàñ‰πåÂÖãÂÖ∞ËØ≠„ÄÇ\n",
    "\n",
    "TensorFlowÊèê‰æõ‰∫Ütf.strings.unicode_scriptÁ°ÆÂÆöÁªôÂÆö‰ª£Á†ÅÁÇπ‰ΩøÁî®Âì™‰∏™ËÑöÊú¨ÁöÑÊìç‰Ωú„ÄÇËÑöÊú¨‰ª£Á†ÅÊòØint32‰∏éUnicodeÂõΩÈôÖÁªÑ‰ª∂ÔºàICUÔºâUScriptCodeÂÄºÁõ∏ÂØπÂ∫îÁöÑÂÄº„ÄÇ\n",
    "## ÁÆÄÂçïËØ¥Â∞±ÊòØÊ†πÊçÆÂ≠óÁ¨¶ÁºñÁ†ÅÁ°ÆÂÆöÂ±û‰∫éÂì™ÁßçËØ≠Ë®Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7DeYHrRyFPy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['Ëä∏', '–ë']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fW992a1lIY6"
   },
   "source": [
    "ËØ•tf.strings.unicode_scriptÊìç‰Ωú‰πüÂèØ‰ª•Â∫îÁî®‰∫étf.Tensor‰∏Ä‰∏™Êàñtf.RaggedTensorÂ§ö‰∏™Á†ÅÁÇπÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uR7b8meLlFnp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mx7HEFpBzEsB"
   },
   "source": [
    "## Á§∫‰æãÔºöÁÆÄÂçïÁªÜÂàÜ\n",
    "ÂàÜÊÆµÊòØÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫Á±ª‰ººÂçïËØçÁöÑÂçïÂÖÉÁöÑ‰ªªÂä°„ÄÇÂΩì‰ΩøÁî®Á©∫Ê†ºÂ≠óÁ¨¶ÂàÜÈöîÂçïËØçÊó∂ÔºåËøôÈÄöÂ∏∏ÂæàÂÆπÊòìÔºå‰ΩÜÊòØÊüê‰∫õËØ≠Ë®ÄÔºàÂ¶Ç‰∏≠ÊñáÂíåÊó•ËØ≠Ôºâ‰∏ç‰ΩøÁî®Á©∫Ê†ºÔºåËÄåÊüê‰∫õËØ≠Ë®ÄÔºàÂ¶ÇÂæ∑ËØ≠ÔºâÂåÖÂê´ÂøÖÈ°ªÂàÜËß£ÊâçËÉΩÂàÜÊûê‚Äã‚ÄãÂÖ∂Âê´‰πâÁöÑÈïøÂåñÂêàÁâ©„ÄÇÂú®ÁΩëÁªúÊñáÊú¨‰∏≠ÔºåÁªèÂ∏∏Â∞Ü‰∏çÂêåÁöÑËØ≠Ë®ÄÂíåËÑöÊú¨Ê∑∑ÂêàÂú®‰∏ÄËµ∑Ôºå‰æãÂ¶Ç‚Äú NYÊ†™‰æ°‚ÄùÔºàÁ∫ΩÁ∫¶ËØÅÂà∏‰∫§ÊòìÊâÄÔºâ„ÄÇ\n",
    "\n",
    "ÈÄöËøá‰ΩøÁî®ËÑöÊú¨‰∏≠ÁöÑÊõ¥ÊîπÊù•Ëøë‰ººÂçïËØçËæπÁïåÔºåÊàë‰ª¨ÂèØ‰ª•ÊâßË°åÈùûÂ∏∏Á≤óÁï•ÁöÑÁªÜÂàÜÔºàÊó†ÈúÄÂÆûÁé∞‰ªª‰ΩïMLÊ®°ÂûãÔºâ„ÄÇËøôÂ∞ÜÈÄÇÁî®‰∫é‰∏äÈù¢ÁöÑ‚Äú NYÊ†™‰æ°‚ÄùÁ§∫‰æã‰πãÁ±ªÁöÑÂ≠óÁ¨¶‰∏≤„ÄÇÂÆÉ‰πüÈÄÇÁî®‰∫éÂ§ßÂ§öÊï∞‰ΩøÁî®Á©∫Ê†ºÁöÑËØ≠Ë®ÄÔºåÂõ†‰∏∫ÂêÑÁßçËÑöÊú¨ÁöÑÁ©∫Ê†ºÂ≠óÁ¨¶ÈÉΩÂΩíÁ±ª‰∏∫USCRIPT_COMMONÔºåËøôÊòØ‰∏ÄÁßçÁâπÊÆäÁöÑËÑöÊú¨‰ª£Á†ÅÔºå‰∏çÂêå‰∫é‰ªª‰ΩïÂÆûÈôÖÁöÑÊñáÊú¨„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grsvFiC4BoPb"
   },
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "#\n",
    "# The sentences to process.  Edit this line to try out different inputs!\n",
    "sentence_texts = ['Hello, world.', '‰∏ñÁïå„Åì„Çì„Å´„Å°„ÅØ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CapnbShuGU8i"
   },
   "source": [
    "È¶ñÂÖàÔºåÊàë‰ª¨Â∞ÜÂè•Â≠êËß£Á†Å‰∏∫Â≠óÁ¨¶‰ª£Á†ÅÁÇπÔºåÁÑ∂Âêé‰∏∫ÊØè‰∏™Â≠óÁ¨¶ÊâæÂà∞ËÑöÊú¨Ê†áËØÜ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReQVcDQh1MB8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] is the codepoint for the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_scripts[i, j] is the unicode script of the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2fapF5UGcUc"
   },
   "source": [
    "Êé•‰∏ãÊù•ÔºåÊàë‰ª¨‰ΩøÁî®Ëøô‰∫õËÑöÊú¨Ê†áËØÜÁ¨¶Êù•Á°ÆÂÆöÂ∫îÂú®‰ΩïÂ§ÑÊ∑ªÂä†ÂçïËØçËæπÁïå„ÄÇÊàë‰ª¨Âú®ÊØè‰∏™Âè•Â≠êÁöÑÂºÄÂ§¥‰ª•ÂèäËÑöÊú¨‰∏é‰∏ä‰∏Ä‰∏™Â≠óÁ¨¶‰∏çÂêåÁöÑÊØè‰∏™Â≠óÁ¨¶Â§ÑÊ∑ªÂä†ÂçïËØçËæπÁïåÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7v5W6MOr1Rlc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n",
    "# sentence is the start of a word.\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] is the index of the character that starts the i'th word (in\n",
    "# the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAwh-1QkGuC9"
   },
   "source": [
    "ÁÑ∂ÂêéÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Ëøô‰∫õËµ∑ÂßãÂÅèÁßªÈáèÊù•ÊûÑÂª∫‰∏Ä‰∏™RaggedTensorÂåÖÂê´ÊâÄÊúâÊâπÊ¨°ÁöÑÂçïËØçÂàóË°®ÁöÑÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNiA1O_eBBCL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
    "# i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_char_codepoint.values,\n",
    "    row_starts=word_starts)\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "66a2ZnYmG2ao"
   },
   "source": [
    "ÊúÄÂêéÔºåÊàë‰ª¨ÂèØ‰ª•Â∞Ü‰ª£Á†ÅÁÇπ‰∏ÄËØçÁªÜÂàÜRaggedTensor‰∏∫Âè•Â≠êÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCfwcqLSEjZb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWaX8WcbHyqY"
   },
   "source": [
    "‰∏∫‰∫Ü‰ΩøÊúÄÁªàÁªìÊûúÊõ¥Êòì‰∫éÈòÖËØªÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÂÖ∂ÁºñÁ†ÅÂõûUTF-8Â≠óÁ¨¶‰∏≤Ôºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSivquOgFr3C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hello', b', ', b'world', b'.'],\n",
       " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
       "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oL9KopJirB2g"
   ],
   "name": "unicode.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
