{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归模型，自定义梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.2\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in np, pd ,sklearn, tf, keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all,x_test,y_train_all,y_test=train_test_split(housing.data, housing.target,random_state=7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all,y_train_all,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "transfer = StandardScaler()\n",
    "x_train_scaled = transfer.fit_transform(x_train)\n",
    "x_test_scaled = transfer.transform(x_test)\n",
    "x_valid_scaled = transfer.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#metric的使用, 均方差\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5.],[2.]))\n",
    "print(metric([0.],[1.]))\n",
    "#之前结果会累加记录\n",
    "print(metric.result())\n",
    "#如果不想累加\n",
    "metric.reset_states()#清空\n",
    "metric([1.],[3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " Epoch 0 train_loss 1.7642136 train mse: 1.6223273  /t valid mse:  1.530690806061189\n",
      " Epoch 1 train_loss 3.8490808 train mse: 5.4682555  /t valid mse:  2.956105838713065\n",
      " Epoch 2 train_loss 1.2618407 train mse: 1.75555 39 /t valid mse:  1.5646127585395502\n",
      " Epoch 3 train_loss 0.7100762 train mse: 1.7005972  /t valid mse:  1.491883889596949\n",
      " Epoch 4 train_loss 1.9047118 train mse: 1.3167212  /t valid mse:  1.4087120753929327\n",
      " Epoch 5 train_loss 1.4936867 train mse: 1.314371   /t valid mse:  1.4031952160410883\n",
      " Epoch 6 train_loss 1.3608087 train mse: 1.2869843  /t valid mse:  1.4075955692559812\n",
      " Epoch 7 train_loss 1.3705614 train mse: 1.2894548  /t valid mse:  1.3954871539160991\n",
      " Epoch 8 train_loss 1.4454876 train mse: 1.3117502  /t valid mse:  1.4003087169859583\n",
      " Epoch 9 train_loss 1.8232844 train mse: 1.2651846  /t valid mse:  1.389847681557242\n",
      " Epoch 10 train_loss 1.3935175 train mse: 1.2645872  /t valid mse:  1.3887294652387614\n",
      " Epoch 11 train_loss 1.0862474 train mse: 1.2320784  /t valid mse:  1.3948354516312946\n",
      " Epoch 12 train_loss 1.4011629 train mse: 1.270399   /t valid mse:  1.3898642302040882\n",
      " Epoch 13 train_loss 0.8210715 train mse: 1.2512742  /t valid mse:  1.3977075273589021\n",
      " Epoch 14 train_loss 1.1272885 train mse: 1.2581748   /t valid mse:  1.3884145439097486\n"
     ]
    }
   ],
   "source": [
    "# 1、batch的形式遍历数据集 metric\n",
    "#      1.1自动求导替换为手动改求导\n",
    "# 2、epich结束，验证集验证 metric\n",
    "\n",
    "epochs = 15\n",
    "batch_size =32\n",
    "steps_per_epoch = len(x_test_scaled) //batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "def random_batch(x,y, batch_size=32):\n",
    "    idx = np.random.randint(0,len(x),size = batch_size)\n",
    "    return x[idx], y[idx] \n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation='relu',input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch, y_batch = random_batch(x_train_scaled, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss  = tf.reduce_mean(# 降低均值\n",
    "#                 tf.reduce_mean 函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，\n",
    "#                 默认axis=None, keep_dims=False,计算所有元素的均值\n",
    "                    keras.losses.mean_squared_error(y_batch, y_pred))\n",
    "            metric(y_batch,y_pred)\n",
    "        grads = tape.gradient(loss, model.variables)#自动求解每个变量和loss的梯度\n",
    "        grads_and_vars = zip(grads, model.variables )#将变量与梯度对应，\n",
    "        optimizer.apply_gradients(grads_and_vars)#使用optimizer.apply_gradients完成梯度下降。\n",
    "        print('\\r Epoch',epoch,'train_loss',loss.numpy(),'train mse:',metric.result().numpy(),end = ' ')\n",
    "    y_valid_pred = model(x_valid_scaled)#验证，每周期完成一次验证。\n",
    "    valid_loss  = tf.reduce_mean(\n",
    "            keras.losses.mean_squared_error(y_valid_pred, y_valid))\n",
    "    print('/t', 'valid mse: ', valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
