{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "train_tf = pd.read_csv(TRAIN_DATA_URL)\n",
    "test_data = pd.read_csv(TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 10)\n",
      "(264, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_tf.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived              0\n",
       "sex                   0\n",
       "age                   0\n",
       "n_siblings_spouses    0\n",
       "parch                 0\n",
       "fare                  0\n",
       "class                 0\n",
       "deck                  0\n",
       "embark_town           0\n",
       "alone                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf[train_tf.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_tf[:500]\n",
    "valid_data = train_tf[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n",
      "(127, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= train_data.pop('survived')\n",
    "y_test = test_data.pop('survived')\n",
    "y_valid= valid_data.pop('survived')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['sex','n_siblings_spouses','parch','class','deck','embark_town']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []#收集所有feature，以运用到dataset上\n",
    "#对离散特征进行onehot 编码处理\n",
    "for column in categorical_columns:\n",
    "    vocab = train_data[column].unique()#用unique取出唯一值\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(column, vocab)))\n",
    "    \n",
    "#categorical_column_with_vocabulary_list提取特征list\n",
    "# indicator_column 对离散特征进行one_hot编码\n",
    "\n",
    "#对连续型特征直接封装\n",
    "for column in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(column, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集.from_tensor_slices()传入字典\n",
    "def make_datasets(x, y, epochs = 10, shuffle = True, batch_size = 32 ):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=8938, shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: id=8930, shape=(5,), dtype=float64, numpy=array([34., 28., 30., 51., 37.])>, 'n_siblings_spouses': <tf.Tensor: id=8936, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 1], dtype=int32)>, 'parch': <tf.Tensor: id=8937, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 1, 0], dtype=int32)>, 'fare': <tf.Tensor: id=8935, shape=(5,), dtype=float64, numpy=array([ 6.4958,  0.    , 13.    , 61.3792, 53.1   ])>, 'class': <tf.Tensor: id=8932, shape=(5,), dtype=string, numpy=array([b'Third', b'Second', b'Second', b'First', b'First'], dtype=object)>, 'deck': <tf.Tensor: id=8933, shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'unknown', b'C'], dtype=object)>, 'embark_town': <tf.Tensor: id=8934, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: id=8931, shape=(5,), dtype=string, numpy=array([b'y', b'y', b'y', b'n', b'n'], dtype=object)>}  \n",
      "\n",
      "\n",
      " tf.Tensor([0 0 0 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "train_dataset = make_datasets(train_data, y_train, batch_size = 5)\n",
    "for x,y in train_dataset.take(1):\n",
    "    print(x, ' \\n\\n\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[93.5   ]\n",
      " [13.    ]\n",
      " [82.1708]\n",
      " [16.1   ]\n",
      " [31.    ]], shape=(5, 1), dtype=float32)\n",
      "WARNING:tensorflow:Layer dense_features_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]], shape=(5, 2), dtype=float32)\n",
      "WARNING:tensorflow:Layer dense_features_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "# keras.layers.DenseFeature可以吧feature运用到datasets上,对离散型特征进行了one_hot编码，连续型特征数值类型转化\n",
    "for x,y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    class_column = feature_columns[3]\n",
    "    \n",
    "    print(keras.layers.DenseFeatures(age_column)(x))#把age的特征用在x上\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x))\n",
    "    print(keras.layers.DenseFeatures(class_column)(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[ 14.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.       0.       0.       1.       0.       0.       0.\n",
      "  120.       1.       0.       0.       0.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       1.    ]\n",
      " [ 47.       0.       1.       0.       0.       0.       0.       0.\n",
      "    0.       1.       0.       0.       1.       0.       0.       0.\n",
      "   34.0208   0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.       0.       0.       0.       0.       1.       0.    ]\n",
      " [ 58.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.       0.       0.       0.       1.       0.       0.\n",
      "   29.7      0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.       0.       0.       0.       0.       1.       0.    ]\n",
      " [ 34.       1.       0.       0.       1.       0.       0.       0.\n",
      "    0.       0.       0.       0.       1.       0.       0.       0.\n",
      "    6.4958   0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.       0.       0.       0.       0.       1.       0.    ]\n",
      " [ 71.       0.       1.       0.       1.       0.       0.       0.\n",
      "    0.       0.       0.       0.       0.       1.       0.       0.\n",
      "   49.5042   0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.       0.       0.       0.       0.       1.       0.    ]], shape=(5, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "# keras.layers.DenseFeature\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                     optimizer = keras.optimizers.SGD(lr = 1e-2),\n",
    "                      metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 15 steps, validate for 3 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6599 - accuracy: 0.6500 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6114 - val_accuracy: 0.6771\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6098 - accuracy: 0.6896 - val_loss: 0.5594 - val_accuracy: 0.7292\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6159 - accuracy: 0.6750 - val_loss: 0.6317 - val_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6376 - accuracy: 0.6479 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6321 - accuracy: 0.6500 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6122 - accuracy: 0.6833 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6458 - accuracy: 0.6500 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6184 - accuracy: 0.6750 - val_loss: 0.6058 - val_accuracy: 0.7396\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6023 - accuracy: 0.6687 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6046 - accuracy: 0.6792 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5978 - accuracy: 0.6896 - val_loss: 0.5862 - val_accuracy: 0.6771\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6504 - accuracy: 0.6354 - val_loss: 0.5415 - val_accuracy: 0.7708\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5909 - accuracy: 0.6729 - val_loss: 0.4996 - val_accuracy: 0.7812\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5970 - accuracy: 0.7167 - val_loss: 0.5316 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6011 - accuracy: 0.6833 - val_loss: 0.4796 - val_accuracy: 0.7917\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6200 - accuracy: 0.6729 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5952 - accuracy: 0.6771 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5972 - accuracy: 0.6667 - val_loss: 0.6365 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5911 - accuracy: 0.6771 - val_loss: 0.5344 - val_accuracy: 0.8021\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6086 - accuracy: 0.6646 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5802 - accuracy: 0.7063 - val_loss: 0.4813 - val_accuracy: 0.7812\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6121 - accuracy: 0.6750 - val_loss: 0.5176 - val_accuracy: 0.7083\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5982 - accuracy: 0.6708 - val_loss: 0.4842 - val_accuracy: 0.7917\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5808 - accuracy: 0.6792 - val_loss: 0.4694 - val_accuracy: 0.7917\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6041 - accuracy: 0.6854 - val_loss: 0.4793 - val_accuracy: 0.7917\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5886 - accuracy: 0.6542 - val_loss: 0.4715 - val_accuracy: 0.7812\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5845 - accuracy: 0.7125 - val_loss: 0.4797 - val_accuracy: 0.8021\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6085 - accuracy: 0.6771 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5778 - accuracy: 0.6917 - val_loss: 0.4764 - val_accuracy: 0.7917\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5799 - accuracy: 0.6771 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6289 - accuracy: 0.6479 - val_loss: 0.4670 - val_accuracy: 0.7812\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6029 - accuracy: 0.6875 - val_loss: 0.5742 - val_accuracy: 0.7604\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5819 - accuracy: 0.6854 - val_loss: 0.4949 - val_accuracy: 0.7917\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5862 - accuracy: 0.6833 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6070 - accuracy: 0.7000 - val_loss: 0.4987 - val_accuracy: 0.8125\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5871 - accuracy: 0.7146 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5667 - accuracy: 0.7000 - val_loss: 0.4669 - val_accuracy: 0.7917\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6107 - accuracy: 0.6833 - val_loss: 0.4689 - val_accuracy: 0.7708\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5927 - accuracy: 0.6771 - val_loss: 0.4787 - val_accuracy: 0.7917\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5664 - accuracy: 0.7063 - val_loss: 0.4729 - val_accuracy: 0.7917\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5392 - accuracy: 0.7229 - val_loss: 0.4606 - val_accuracy: 0.7917\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5676 - accuracy: 0.7146 - val_loss: 0.4547 - val_accuracy: 0.7917\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5975 - accuracy: 0.6750 - val_loss: 0.4554 - val_accuracy: 0.7917\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5806 - accuracy: 0.6854 - val_loss: 0.4969 - val_accuracy: 0.7292\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5446 - accuracy: 0.7375 - val_loss: 0.4664 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5982 - accuracy: 0.7000 - val_loss: 0.4792 - val_accuracy: 0.8125\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5704 - accuracy: 0.7104 - val_loss: 0.4868 - val_accuracy: 0.7604\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5698 - accuracy: 0.7250 - val_loss: 0.5134 - val_accuracy: 0.7917\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5831 - accuracy: 0.7042 - val_loss: 0.4510 - val_accuracy: 0.8125\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5674 - accuracy: 0.7021 - val_loss: 0.4473 - val_accuracy: 0.7917\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5813 - accuracy: 0.6896 - val_loss: 0.4989 - val_accuracy: 0.8229\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5683 - accuracy: 0.7188 - val_loss: 0.4878 - val_accuracy: 0.8229\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5526 - accuracy: 0.7250 - val_loss: 0.4732 - val_accuracy: 0.8229\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5505 - accuracy: 0.7354 - val_loss: 0.4448 - val_accuracy: 0.8021\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5610 - accuracy: 0.6812 - val_loss: 0.5500 - val_accuracy: 0.7708\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6317 - accuracy: 0.6792 - val_loss: 0.5415 - val_accuracy: 0.8021\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.6854 - val_loss: 0.4791 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5572 - accuracy: 0.7188 - val_loss: 0.4385 - val_accuracy: 0.8021\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5520 - accuracy: 0.7188 - val_loss: 0.4471 - val_accuracy: 0.8125\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5772 - accuracy: 0.6958 - val_loss: 0.5558 - val_accuracy: 0.7708\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5620 - accuracy: 0.7146 - val_loss: 0.4739 - val_accuracy: 0.8021\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5590 - accuracy: 0.6938 - val_loss: 0.4429 - val_accuracy: 0.8021\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5938 - accuracy: 0.7000 - val_loss: 0.4957 - val_accuracy: 0.8021\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5479 - accuracy: 0.7188 - val_loss: 0.4707 - val_accuracy: 0.8021\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5516 - accuracy: 0.7188 - val_loss: 0.4658 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5793 - accuracy: 0.7042 - val_loss: 0.4855 - val_accuracy: 0.8125\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5883 - accuracy: 0.7104 - val_loss: 0.4838 - val_accuracy: 0.8021\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5313 - accuracy: 0.7271 - val_loss: 0.4509 - val_accuracy: 0.8021\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5919 - accuracy: 0.6875 - val_loss: 0.4502 - val_accuracy: 0.8021\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5978 - accuracy: 0.7167 - val_loss: 0.4726 - val_accuracy: 0.8021\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5715 - accuracy: 0.6938 - val_loss: 0.4743 - val_accuracy: 0.7917\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5292 - accuracy: 0.7354 - val_loss: 0.5075 - val_accuracy: 0.7812\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5492 - accuracy: 0.7125 - val_loss: 0.4518 - val_accuracy: 0.8229\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5398 - accuracy: 0.7271 - val_loss: 0.6194 - val_accuracy: 0.6771\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6036 - accuracy: 0.6917 - val_loss: 0.5554 - val_accuracy: 0.7604\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5547 - accuracy: 0.6938 - val_loss: 0.5089 - val_accuracy: 0.7917\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5472 - accuracy: 0.7208 - val_loss: 0.4367 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5854 - accuracy: 0.6958 - val_loss: 0.4574 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5639 - accuracy: 0.7333 - val_loss: 0.4762 - val_accuracy: 0.8229\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5229 - accuracy: 0.7479 - val_loss: 0.4319 - val_accuracy: 0.7917\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5595 - accuracy: 0.7229 - val_loss: 0.4741 - val_accuracy: 0.7396\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5686 - accuracy: 0.7000 - val_loss: 0.4520 - val_accuracy: 0.8125\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5389 - accuracy: 0.7292 - val_loss: 0.4377 - val_accuracy: 0.7917\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5520 - accuracy: 0.7104 - val_loss: 0.5422 - val_accuracy: 0.7708\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5634 - accuracy: 0.7167 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6209 - accuracy: 0.7021 - val_loss: 0.4625 - val_accuracy: 0.8229\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5528 - accuracy: 0.7250 - val_loss: 0.4355 - val_accuracy: 0.8021\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5090 - accuracy: 0.7500 - val_loss: 0.4417 - val_accuracy: 0.7812\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6119 - accuracy: 0.6687 - val_loss: 0.4482 - val_accuracy: 0.8021\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5220 - accuracy: 0.7667 - val_loss: 0.4175 - val_accuracy: 0.8125\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5534 - accuracy: 0.7146 - val_loss: 0.4321 - val_accuracy: 0.8021\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5146 - accuracy: 0.7417 - val_loss: 0.4323 - val_accuracy: 0.8229\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5425 - accuracy: 0.7104 - val_loss: 0.4247 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5346 - accuracy: 0.7250 - val_loss: 0.4799 - val_accuracy: 0.7812\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5689 - accuracy: 0.7229 - val_loss: 0.4216 - val_accuracy: 0.8021\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5416 - accuracy: 0.7354 - val_loss: 0.4418 - val_accuracy: 0.8229\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5501 - accuracy: 0.7312 - val_loss: 0.4458 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5548 - accuracy: 0.7125 - val_loss: 0.4355 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5316 - accuracy: 0.7417 - val_loss: 0.4402 - val_accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "#1、model.fit\n",
    "train_dataset = make_datasets(train_data, y_train,epochs=100)\n",
    "valid_dataset = make_datasets(valid_data, y_valid,epochs=1,shuffle=False)\n",
    "test_dataset = make_datasets(test_data, y_test,epochs=1,shuffle=False)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=valid_dataset,\n",
    "                    steps_per_epoch=500//32,\n",
    "                    epochs=100,\n",
    "                    validation_steps = 127//32\n",
    "                   )#steps_per_epoch=训练集的样本数//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/l7/d1pnsddn4wd3z6qry0tp5rvh0000gn/T/tmprz3hfmkf\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/l7/d1pnsddn4wd3z6qry0tp5rvh0000gn/T/tmprz3hfmkf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x641d13d10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b1e979a342d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmake_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# estimator.train(input_fn = lambda: make_datasets(train_data, y_train, epochs=100))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1190\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 419\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    420\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mytf/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[1;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m--> 987\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "# 2.model -> estimator ->train\n",
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "\n",
    "# def input_fn():\n",
    "#   return make_datasets(train_data, y_train,epochs=100)\n",
    "# estimator.train(input_fn)\n",
    "\n",
    "estimator.train(input_fn = lambda: make_datasets(train_data, y_train, epochs=100))\n",
    "#参数只有一个input_fn：1、是一个函数\n",
    "#                            2、返回元组（features,labels）或（feature,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({sex: (None,), age: (None,), n_siblings_spouses: (None,), parch: (None,), fare: (None,), class: (None,), deck: (None,), embark_town: (None,), alone: (None,)}, (None,)), types: ({sex: tf.string, age: tf.float64, n_siblings_spouses: tf.int32, parch: tf.int32, fare: tf.float64, class: tf.string, deck: tf.string, embark_town: tf.string, alone: tf.string}, tf.int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('mytf': conda)",
   "language": "python",
   "name": "python37664bitmytfconda841baf2f843f47f398642a391af5d6cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
