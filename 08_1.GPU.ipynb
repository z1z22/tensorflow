{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默认只使用一个gpu，且全部占满\n",
    "## 1、如何不浪费内存和计算资源\n",
    "### 内存自增长\n",
    "### 虚拟设备机制\n",
    "## 2、多gpu使用\n",
    "### 虚拟gpu & 实际gpu\n",
    "### 手工设置 & 分布式机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow  as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement# 打印日志\n",
    "tf.config.experimental.set_visible_devices# 设置对于本进程所见的设备\n",
    "tf.config.experimental.list_logical_devices# 获取所有的逻辑设备\n",
    "tf.config.experimental.list_physical_devices# 获取物理设备列表\n",
    "tf.config.experimental.set_memory_growth# 内存自增\n",
    "tf.config.experimental.VirtualDeviceConfiguration# 见了逻辑分区\n",
    "tf.config.set_soft_device_placement# 自动把计算分配到某个设备\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分布式策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提高训练速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、MirroredStrategy \n",
    "### 同步式分布式策略，适用于一级多卡情况\n",
    "### 每个GPU上有网络结构的所有参数，这些参数会被同步\n",
    "### 数据并行：\n",
    "#### batch切分数据分给每个GPU\n",
    "#### 梯度聚合然后跟新给各个GPU上的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、CentralStrategy\n",
    "## MirroredStrategy的变种\n",
    "## 参数不在每个GPU上，而是存储在一个设备上 CPU上\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3、MultiWorkerMirroredStrategy\n",
    "## MirroredStrategy的变种\n",
    "## 适用于多台机器\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4、TPUStrategy\n",
    "## 和MirroredStrategy类似\n",
    "### 使用TPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5、ParameterServerStrategy\n",
    "## 异步分布式\n",
    "## 更加适用于大规模分布式系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
