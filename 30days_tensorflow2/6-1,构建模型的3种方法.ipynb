{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-1,构建模型的3种方法\n",
    "\n",
    "可以使用以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n",
    "\n",
    "对于顺序结构的模型，优先使用Sequential方法构建。\n",
    "\n",
    "如果模型有多输入或者多输出，或者模型需要共享权重，或者模型具有残差连接等非顺序结构，推荐使用函数式API进行创建。\n",
    "\n",
    "如果无特定必要，尽可能避免使用Model子类化的方式构建模型，这种方式提供了极大的灵活性，但也有更大的概率出错。\n",
    "\n",
    "下面以IMDB电影评论的分类问题为例，演示3种创建模型的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm \n",
    "from tensorflow.keras import *\n",
    "\n",
    "\n",
    "train_token_path = \"./data/imdb/train_token.csv\"\n",
    "test_token_path = \"./data/imdb/test_token.csv\"\n",
    "\n",
    "MAX_WORDS = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "MAX_LEN = 200  # We will cut reviews after 200 words\n",
    "BATCH_SIZE = 20 \n",
    "\n",
    "# 构建管道\n",
    "def parse_line(line):\n",
    "    t = tf.strings.split(line,\"\\t\")\n",
    "    label = tf.reshape(tf.cast(tf.strings.to_number(t[0]),tf.int32),(-1,))\n",
    "    features = tf.cast(tf.strings.to_number(tf.strings.split(t[1],\" \")),tf.int32)\n",
    "    return (features,label)\n",
    "\n",
    "ds_train=  tf.data.TextLineDataset(filenames = [train_token_path]) \\\n",
    "   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n",
    "   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "   .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test=  tf.data.TextLineDataset(filenames = [test_token_path]) \\\n",
    "   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n",
    "   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "   .prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一，Sequential按层顺序创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 7)            70000     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 196, 64)           2304      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 96, 32)            6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1537      \n",
      "=================================================================\n",
      "Total params: 80,017\n",
      "Trainable params: 80,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='Nadam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',\"AUC\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/Sequential模型结构.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "    545/Unknown - 53s 97ms/step - loss: 0.5723 - accuracy: 0.6463 - AUC: 0.7369"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "baselogger = callbacks.BaseLogger(stateful_metrics=[\"AUC\"])\n",
    "logdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "history = model.fit(ds_train,validation_data = ds_test,\n",
    "        epochs = 6,callbacks=[baselogger,tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history,\"AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/6-1-fit模型.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二，函数式API创建任意结构模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=[MAX_LEN])\n",
    "x  = layers.Embedding(MAX_WORDS,7)(inputs)\n",
    "\n",
    "branch1 = layers.SeparableConv1D(64,3,activation=\"relu\")(x)\n",
    "branch1 = layers.MaxPool1D(3)(branch1)\n",
    "branch1 = layers.SeparableConv1D(32,3,activation=\"relu\")(branch1)\n",
    "branch1 = layers.GlobalMaxPool1D()(branch1)\n",
    "\n",
    "branch2 = layers.SeparableConv1D(64,5,activation=\"relu\")(x)\n",
    "branch2 = layers.MaxPool1D(5)(branch2)\n",
    "branch2 = layers.SeparableConv1D(32,5,activation=\"relu\")(branch2)\n",
    "branch2 = layers.GlobalMaxPool1D()(branch2)\n",
    "\n",
    "branch3 = layers.SeparableConv1D(64,7,activation=\"relu\")(x)\n",
    "branch3 = layers.MaxPool1D(7)(branch3)\n",
    "branch3 = layers.SeparableConv1D(32,7,activation=\"relu\")(branch3)\n",
    "branch3 = layers.GlobalMaxPool1D()(branch3)\n",
    "\n",
    "concat = layers.Concatenate()([branch1,branch2,branch3])\n",
    "outputs = layers.Dense(1,activation = \"sigmoid\")(concat)\n",
    "\n",
    "model = models.Model(inputs = inputs,outputs = outputs)\n",
    "\n",
    "model.compile(optimizer='Nadam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',\"AUC\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Model: \"model\"\n",
    "__________________________________________________________________________________________________\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
    "__________________________________________________________________________________________________\n",
    "embedding (Embedding)           (None, 200, 7)       70000       input_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "separable_conv1d (SeparableConv (None, 198, 64)      533         embedding[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "separable_conv1d_2 (SeparableCo (None, 196, 64)      547         embedding[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "separable_conv1d_4 (SeparableCo (None, 194, 64)      561         embedding[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling1d (MaxPooling1D)    (None, 66, 64)       0           separable_conv1d[0][0]           \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling1d_1 (MaxPooling1D)  (None, 39, 64)       0           separable_conv1d_2[0][0]         \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling1d_2 (MaxPooling1D)  (None, 27, 64)       0           separable_conv1d_4[0][0]         \n",
    "__________________________________________________________________________________________________\n",
    "separable_conv1d_1 (SeparableCo (None, 64, 32)       2272        max_pooling1d[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "separable_conv1d_3 (SeparableCo (None, 35, 32)       2400        max_pooling1d_1[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "separable_conv1d_5 (SeparableCo (None, 21, 32)       2528        max_pooling1d_2[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "global_max_pooling1d (GlobalMax (None, 32)           0           separable_conv1d_1[0][0]         \n",
    "__________________________________________________________________________________________________\n",
    "global_max_pooling1d_1 (GlobalM (None, 32)           0           separable_conv1d_3[0][0]         \n",
    "__________________________________________________________________________________________________\n",
    "global_max_pooling1d_2 (GlobalM (None, 32)           0           separable_conv1d_5[0][0]         \n",
    "__________________________________________________________________________________________________\n",
    "concatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n",
    "                                                                 global_max_pooling1d_1[0][0]     \n",
    "                                                                 global_max_pooling1d_2[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "dense (Dense)                   (None, 1)            97          concatenate[0][0]                \n",
    "==================================================================================================\n",
    "Total params: 78,938\n",
    "Trainable params: 78,938\n",
    "Non-trainable params: 0\n",
    "__________________________________________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/FunctionalAPI模型结构.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "logdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "history = model.fit(ds_train,validation_data = ds_test,epochs = 6,callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/6\n",
    "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5527 - accuracy: 0.6758 - AUC: 0.7731 - val_loss: 0.3646 - val_accuracy: 0.8426 - val_AUC: 0.9192\n",
    "Epoch 2/6\n",
    "1000/1000 [==============================] - 24s 24ms/step - loss: 0.3024 - accuracy: 0.8737 - AUC: 0.9444 - val_loss: 0.3281 - val_accuracy: 0.8644 - val_AUC: 0.9350\n",
    "Epoch 3/6\n",
    "1000/1000 [==============================] - 24s 24ms/step - loss: 0.2158 - accuracy: 0.9159 - AUC: 0.9715 - val_loss: 0.3461 - val_accuracy: 0.8666 - val_AUC: 0.9363\n",
    "Epoch 4/6\n",
    "1000/1000 [==============================] - 24s 24ms/step - loss: 0.1492 - accuracy: 0.9464 - AUC: 0.9859 - val_loss: 0.4017 - val_accuracy: 0.8568 - val_AUC: 0.9311\n",
    "Epoch 5/6\n",
    "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0944 - accuracy: 0.9696 - AUC: 0.9939 - val_loss: 0.4998 - val_accuracy: 0.8550 - val_AUC: 0.9233\n",
    "Epoch 6/6\n",
    "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0526 - accuracy: 0.9865 - AUC: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.8462 - val_AUC: 0.9138\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history,\"AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/6-1-2-train.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三，Model子类化创建自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先自定义一个残差模块，为自定义Layer\n",
    "\n",
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, kernel_size, **kwargs):\n",
    "        super(ResBlock, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        self.conv1 = layers.Conv1D(filters=64,kernel_size=self.kernel_size,\n",
    "                                   activation = \"relu\",padding=\"same\")\n",
    "        self.conv2 = layers.Conv1D(filters=32,kernel_size=self.kernel_size,\n",
    "                                   activation = \"relu\",padding=\"same\")\n",
    "        self.conv3 = layers.Conv1D(filters=input_shape[-1],\n",
    "                                   kernel_size=self.kernel_size,activation = \"relu\",padding=\"same\")\n",
    "        self.maxpool = layers.MaxPool1D(2)\n",
    "        super(ResBlock,self).build(input_shape) # 相当于设置self.build = True\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = layers.Add()([inputs,x])\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "    \n",
    "    #如果要让自定义的Layer通过Functional API 组合成模型时可以序列化，需要自定义get_config方法。\n",
    "    def get_config(self):  \n",
    "        config = super(ResBlock, self).get_config()\n",
    "        config.update({'kernel_size': self.kernel_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试ResBlock\n",
    "resblock = ResBlock(kernel_size = 3)\n",
    "resblock.build(input_shape = (None,200,7))\n",
    "resblock.compute_output_shape(input_shape=(None,200,7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TensorShape([None, 100, 7])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义模型，实际上也可以使用Sequential或者FunctionalAPI\n",
    "\n",
    "class ImdbModel(models.Model):\n",
    "    def __init__(self):\n",
    "        super(ImdbModel, self).__init__()\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.embedding = layers.Embedding(MAX_WORDS,7)\n",
    "        self.block1 = ResBlock(7)\n",
    "        self.block2 = ResBlock(5)\n",
    "        self.dense = layers.Dense(1,activation = \"sigmoid\")\n",
    "        super(ImdbModel,self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense(x)\n",
    "        return(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = ImdbModel()\n",
    "model.build(input_shape =(None,200))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='Nadam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',\"AUC\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Model: \"imdb_model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "embedding (Embedding)        multiple                  70000     \n",
    "_________________________________________________________________\n",
    "res_block (ResBlock)         multiple                  19143     \n",
    "_________________________________________________________________\n",
    "res_block_1 (ResBlock)       multiple                  13703     \n",
    "_________________________________________________________________\n",
    "dense (Dense)                multiple                  351       \n",
    "=================================================================\n",
    "Total params: 103,197\n",
    "Trainable params: 103,197\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/Model子类化模型结构.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "logdir = \"./tflogs/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "history = model.fit(ds_train,validation_data = ds_test,\n",
    "                    epochs = 6,callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/6\n",
    "1000/1000 [==============================] - 47s 47ms/step - loss: 0.5629 - accuracy: 0.6618 - AUC: 0.7548 - val_loss: 0.3422 - val_accuracy: 0.8510 - val_AUC: 0.9286\n",
    "Epoch 2/6\n",
    "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2648 - accuracy: 0.8903 - AUC: 0.9576 - val_loss: 0.3276 - val_accuracy: 0.8650 - val_AUC: 0.9410\n",
    "Epoch 3/6\n",
    "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1573 - accuracy: 0.9439 - AUC: 0.9846 - val_loss: 0.3861 - val_accuracy: 0.8682 - val_AUC: 0.9390\n",
    "Epoch 4/6\n",
    "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0849 - accuracy: 0.9706 - AUC: 0.9950 - val_loss: 0.5324 - val_accuracy: 0.8616 - val_AUC: 0.9292\n",
    "Epoch 5/6\n",
    "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - AUC: 0.9986 - val_loss: 0.7693 - val_accuracy: 0.8566 - val_AUC: 0.9132\n",
    "Epoch 6/6\n",
    "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0222 - accuracy: 0.9926 - AUC: 0.9994 - val_loss: 0.9328 - val_accuracy: 0.8584 - val_AUC: 0.9052\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history,\"AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/6-1-3-fit模型.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('mytf': conda)",
   "language": "python",
   "name": "python37664bitmytfconda841baf2f843f47f398642a391af5d6cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
